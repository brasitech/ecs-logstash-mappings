# Corelight ECS Logstash Pipeline
# Git Repository: https://github.com/corelight/ecs-logstash-mappings
# Authors: Corelight Inc, Brasi Tech LLC
# License: BSD 3-Clause
# Support: https://github.com/corelight/ecs-logstash-mappings/issues/new
# Releases: https://github.com/corelight/ecs-logstash-mappings/releases

input {
  kafka {
    ################## Topics ##################
    # Topic(s) to consume from using array
    #topics => [ "${LS_INPUT_KAFKA_TOPICS}" ]
    #topics => [ "corelight" ]
    # Topic(s) to consume from using (regex) pattern
    #topics_pattern => "${LS_INPUT_KAFKA_TOPICS_PATTERN}"
    #topics_pattern => "corelight_(conn|ssl|files|x509|http|dns).*"

    ################## Consumer Threads ##################
    # This setting should match the number of Kafka partitions for the topic(s) you are consuming from.
    # Change this if you have customized the number of kafka partitions for the topic AND are needing to scale (up) consumption
    # Read documentation for more info: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html#plugins-inputs-kafka-consumer_threads
    consumer_threads => "${LS_INPUT_KAFKA_CONSUMER_THREAD}"
    #consumer_threads => 3

    ################## Kafka Servers ##################
    bootstrap_servers => "${LS_INPUT_KAFKA_BOOTSTRAP_SERVERS}"
    #bootstrap_servers => "localhost:9092"
    #bootstrap_servers => "localhost:9092,localhost:9093,localhost:9094" #:Example:# kafka (cluster) with multiple nodes


    # Set to the naming convention that best suites your environment
    group_id => "${LS_INPUT_KAFKA_GROUP_ID}"
    #group_id => "logstash_corelight_group"
    # Set unique per logstash instance
    client_id => "${LS_INPUT_KAFKA_client_id}"
    #client_id => "logstash_consumer"


    auto_offset_reset => "${LS_INPUT_KAFKA_AUTO_OFFSET_RESET}"
    #auto_offset_reset => "earliest"
    decorate_events => "${LS_INPUT_KAFKA_DECORATE_EVENTS}"
    #decorate_events => "extended" #default: none
    enable_auto_commit => "${LS_INPUT_KAFKA_ENABLE_AUTO_COMMIT}" #true
    #enable_auto_commit => true
    max_poll_records => "${LS_INPUT_KAFKA_MAX_POLL_RECORDS}" #default: 500
    #max_poll_records => 500 #default: 500

    #fetch_min_bytes => "${LS_INPUT_KAFKA_FETCH_MIN_BYTES}" #"" #default: none
    #group_instance_id => "${LS_INPUT_KAFKA_GROUP_INSTANCE_ID}" #"" #default: none
    #auto_commit_interval_ms => "${LS_INPUT_KAFKA_AUTO_COMMIT_INTERVAL_MS}" #5000 #default: 5000 #5 seconds
    #check_crcs => "${LS_INPUT_KAFKA_CHECK_CRCS}" #true #default: true
    #client_dns_lookup => "${LS_INPUT_KAFKA_CLIENT_DNS_LOOKUP}" #"default" #default: default
    #connections_max_idle_ms => "${LS_INPUT_KAFKA_CONNECTIONS_MAX_IDLE_MS}" #540000 #default: 540000 #9 minutes
    #fetch_max_bytes => "${LS_INPUT_KAFKA_FETCH_MAX_BYTES}" #52428800 #default: 52428800 #50MB
    #fetch_max_wait_ms => "${LS_INPUT_KAFKA_FETCH_MAX_WAIT_MS}" #500 #default: 500 #.5 seconds
    #heartbeat_interval_ms => "${LS_INPUT_KAFKA_HEARTBEAT_INTERVAL_MS}" #3000 #default: 3000 #3 seconds
    #max_partition_fetch_bytes => "${LS_INPUT_KAFKA_MAX_PARTITION_FETCH_BYTES}" #1048576 #default: 1048576 #1MB
    #max_poll_interval_ms => "${LS_INPUT_KAFKA_MAX_POLL_INTERVAL_MS}" #300000 #default: 300000 #5 minutes
    #metadata_max_age_ms => "${LS_INPUT_KAFKA_METADATA_MAX_AGE_MS}" #300000 #default: 300000 #5 minutes
    #partition_assignment_strategy => "${LS_INPUT_KAFKA_PARTITION_ASSIGNMENT_STRATEGY}" #"" #default: "" #none
    #poll_timeout_ms => "${LS_INPUT_KAFKA_POLL_TIMEOUT_MS}" #100 #default: 100 #.1 seconds
    #receive_buffer_bytes => "${LS_INPUT_KAFKA_RECEIVE_BUFFER_BYTES}" #32768 #default: 32768 #32KB
    #reconnect_backoff_ms => "${LS_INPUT_KAFKA_RECONNECT_BACKOFF_MS}" #50 #default: 50 #.005 seconds
    #request_timeout_ms => "${LS_INPUT_KAFKA_REQUEST_TIMEOUT_MS}" #40000 #default: 40000 #4 seconds
    #retry_backoff_ms => "${LS_INPUT_KAFKA_RETRY_BACKOFF_MS}" #100 #default: 100 #.1 seconds
    #security_protocol => "${LS_INPUT_KAFKA_SECURITY_PROTOCOL}" #"PLAINTEXT" #default: PLAINTEXT
    #send_buffer_bytes => "${LS_INPUT_KAFKA_SEND_BUFFER_BYTES}" #131072 #default 131072 #128KB
    #session_timeout_ms => "${LS_INPUT_KAFKA_SESSION_TIMEOUT_MS}" #10000 #default: 10000 #10 seconds

    ################ Required fields, do not modify these ################
    #codec => "json"
    add_field => {
      "[@metadata][etl][input_application_protocol]" => "kafka"
      "[@metadata][z_no_reuse][event_type]" => "corelight"
      "[@metadata][etl][pipeline]" => "input-kafka-58e9c96224f4-2023120101"
    }
    ################ END Required fields, do not modify these ################
    id => "input-kafka-58e9c96224f4"
  }
}
